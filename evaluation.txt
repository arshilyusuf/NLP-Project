======================================================================
HINDI SARCASM DETECTION MODEL - PERFORMANCE METRICS
======================================================================

ðŸ“¦ Loading trained model...
âœ“ Model loaded successfully!

ðŸ“Š Loading test dataset from {test_csv_path}...
âœ“ Loaded 2319 test samples

ðŸ”§ Preprocessing texts...

ðŸ“ˆ Test samples: 2319
[NLP] Extracting comprehensive NLP features for test set...
Engineered feature dimensions for test set: (2319, 24)

ðŸ”„ Transforming texts to TF-IDF features...
TF-IDF feature dimensions for test set: (2319, 10000)
Combined feature dimensions for test set: (2319, 10024)

ðŸ”® Making predictions...

======================================================================
PERFORMANCE METRICS
======================================================================

ðŸ“Š TEST SET PERFORMANCE:
   Accuracy:  0.9733 (97.33%)
   Precision: 0.9569 (95.69%)
   Recall:    0.9741 (97.41%)
   F1-Score:  0.9654 (96.54%)
   ROC-AUC:   0.9908 (99.08%)

======================================================================
DETAILED CLASSIFICATION REPORT (Test Set)
======================================================================
               precision    recall  f1-score   support

Not Sarcastic     0.9837    0.9727    0.9782      1430
    Sarcastic     0.9569    0.9741    0.9654       889

     accuracy                         0.9733      2319
    macro avg     0.9703    0.9734    0.9718      2319
 weighted avg     0.9734    0.9733    0.9733      2319


======================================================================
CONFUSION MATRIX (Test Set)
======================================================================

                Predicted
              Not Sarc  Sarcastic
Actual Not Sarc   1391        39
      Sarcastic     23       866

----------------------------------------------------------------------
Interpretation:
  True Negatives (TN):  1391 - Correctly identified as Not Sarcastic
  False Positives (FP): 39 - Incorrectly identified as Sarcastic
  False Negatives (FN): 23 - Missed Sarcastic texts
  True Positives (TP):  866 - Correctly identified as Sarcastic

======================================================================
PER-CLASS PERFORMANCE (Test Set)
======================================================================

Not Sarcastic Class:
   Precision: 0.9837 (98.37%)
   Recall:    0.9727 (97.27%)
   F1-Score:  0.9782 (97.82%)

Sarcastic Class:
   Precision: 0.9569 (95.69%)
   Recall:    0.9741 (97.41%)
   F1-Score:  0.9654 (96.54%)

======================================================================
MODEL SUMMARY
======================================================================
âœ… Overall Test Accuracy: 97.33%
âœ… Model Type: Logistic Regression with TF-IDF features
âœ… Feature Extraction: Character n-grams (1-4 grams)
âœ… Max Features: 10,000
âœ… Test Samples: 2319
âœ… Performance Level: Excellent
======================================================================
